{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VcDipb-jJEXn",
        "outputId": "d36a00ce-a284-4359-e2e4-6ce15b27ad51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --quiet langchain_google_genai langchain_community langgraph langgraph-prebuilt pyowm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "\n",
        "GEMINI_API_KEY = getpass.getpass(\"Enter Gemini API Key: \")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GEMINI_API_KEY\n",
        "\n",
        "from langchain_community.utilities import OpenWeatherMapAPIWrapper\n",
        "\n",
        "OPENWEATHERMAP_API_KEY = getpass.getpass(\"Enter OpenWeatherMap API Key: \")\n",
        "os.environ[\"OPENWEATHERMAP_API_KEY\"]=OPENWEATHERMAP_API_KEY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqvAfi7Gf2bb",
        "outputId": "bcafa59d-299b-4676-ceac-15400abe2d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Gemini API Key: ··········\n",
            "Enter OpenWeatherMap API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, Sequence\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.tools.openweathermap import OpenWeatherMapQueryRun\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.graph import StateGraph, END, MessagesState\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "\n",
        "tools = OpenWeatherMapQueryRun(api_key=os.environ[\"OPENWEATHERMAP_API_KEY\"])\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
        "model_with_tools = model.bind_tools([tools])\n",
        "\n",
        "tool_node = ToolNode([tools])\n",
        "\n",
        "def process_user_input(state):\n",
        "    messages = state['messages']\n",
        "    response = model_with_tools.invoke(messages)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "def should_continue(state):\n",
        "    # Determine whether to continue with tool execution or end.\n",
        "    messages = state['messages']\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
        "    if last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "\n",
        "    return END\n",
        "\n",
        "# Create the workflow using StateGraph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes to the workflow\n",
        "workflow.add_node(\"agent\", process_user_input)\n",
        "workflow.add_node(\"tools\", tool_node)\n",
        "\n",
        "# Set the entry point\n",
        "workflow.set_entry_point(\"agent\")\n",
        "\n",
        "# Add conditional edges\n",
        "workflow.add_conditional_edges( \"agent\",\n",
        "                                should_continue,\n",
        "                                {\n",
        "                                  \"tools\": \"tools\",\n",
        "                                  END: END\n",
        "                                }\n",
        "                              )\n",
        "\n",
        "# Add edge from tools back to agent\n",
        "workflow.add_edge('tools', \"agent\")\n",
        "\n",
        "# Compile the workflow\n",
        "app = workflow.compile()\n",
        "\n",
        "inputs = {\"messages\": [HumanMessage(content=\"Hey! how are you?\")]}\n",
        "result = app.invoke(inputs)\n",
        "for m in result['messages']:\n",
        "  m.pretty_print()\n"
      ],
      "metadata": {
        "id": "taLmHQ39KpOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37dd04b8-db32-4458-ef1f-528d9e7bfb83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hey! how are you?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I'm doing well, thank you for asking! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"messages\": [HumanMessage(content=\"What is temperatue in Atlanta\")]}\n",
        "for output in app.stream(inputs):\n",
        "    # stream() yields dictionaries with output keyed by node name\n",
        "    for key, value in output.items():\n",
        "        print(f\"Output from node '{key}':\")\n",
        "        print(\"---\")\n",
        "        print(value)\n",
        "    print(\"\\n---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovk31bJ7LGbO",
        "outputId": "ffc82e55-10fd-4cc7-b098-e08e111a8bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output from node 'agent':\n",
            "---\n",
            "{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'open_weather_map', 'arguments': '{\"location\": \"Atlanta,US\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--1a10646d-54f1-49aa-bb08-f29ac876e0c9-0', tool_calls=[{'name': 'open_weather_map', 'args': {'location': 'Atlanta,US'}, 'id': '6ff5087d-6536-4560-b784-bc0b32d47c3e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 49, 'output_tokens': 9, 'total_tokens': 58, 'input_token_details': {'cache_read': 0}})]}\n",
            "\n",
            "---\n",
            "\n",
            "Output from node 'tools':\n",
            "---\n",
            "{'messages': [ToolMessage(content='In Atlanta,US, the current weather is as follows:\\nDetailed status: overcast clouds\\nWind speed: 2.57 m/s, direction: 260°\\nHumidity: 66%\\nTemperature: \\n  - Current: 26.8°C\\n  - High: 27.72°C\\n  - Low: 25.09°C\\n  - Feels like: 28.24°C\\nRain: {}\\nHeat index: None\\nCloud cover: 100%', name='open_weather_map', tool_call_id='6ff5087d-6536-4560-b784-bc0b32d47c3e')]}\n",
            "\n",
            "---\n",
            "\n",
            "Output from node 'agent':\n",
            "---\n",
            "{'messages': [AIMessage(content='The temperature in Atlanta, US is currently 26.8°C.  It feels like 28.24°C. The high for today is 27.72°C and the low is 25.09°C.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--ca028eab-9161-4813-8d8d-119a8dbceed7-0', usage_metadata={'input_tokens': 183, 'output_tokens': 56, 'total_tokens': 239, 'input_token_details': {'cache_read': 0}})]}\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RPT0UvIK-xNY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}